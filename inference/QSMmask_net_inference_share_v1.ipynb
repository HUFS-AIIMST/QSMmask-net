{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e31101-8030-419e-98c6-d35130d9962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.data import Dataset\n",
    "from monai.networks import nets\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose, \n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    SaveImage,\n",
    "    Orientationd,\n",
    "    FillHoles,\n",
    "    EnsureChannelFirstd,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691840ea-2bc2-4dd1-92f7-d66ed1ea55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b6651",
   "metadata": {},
   "source": [
    "### Load the input data and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "work_root ='...input data path...'\n",
    "valid_brain = glob(f'{work_root}/*.nii.gz')\n",
    "\n",
    "save_dir='...save path...'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#for check\n",
    "a=nib.load(valid_brain[0])\n",
    "affine = a.affine \n",
    "axcodes = nib.aff2axcodes(affine)\n",
    "print(axcodes)\n",
    "original_orientation = axcodes\n",
    "a=a.get_fdata()\n",
    "zs = int(a.shape[2]/2)\n",
    "plt.imshow(a[:,:,zs],cmap='gray')\n",
    "\n",
    "valid_dicts=[\n",
    "    {\"image\": image_name} for image_name in valid_brain\n",
    "]\n",
    "\n",
    "pre_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=('image')),\n",
    "        EnsureChannelFirstd(keys=\"image\"),\n",
    "        Orientationd(keys=('image'), axcodes=('PRS')),\n",
    "        ScaleIntensityd(keys='image'),\n",
    "        ToTensord(keys=('image')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "check_ds = Dataset(data=valid_dicts,transform=pre_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "img=check_ds[0]['image']\n",
    "print(img.shape)\n",
    "plt.figure(dpi=128)\n",
    "plt.imshow(img[0,:,:,zs],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc4fd6",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c795eb7-b519-4667-b661-9a69c8fdf9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(data=valid_dicts, transform=pre_transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=2, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = nets.BasicUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    features=(16,32,64,128,256,32),\n",
    "    ).to(device)\n",
    "\n",
    "post_trans = Compose(\n",
    "    [Activations(sigmoid=True), AsDiscrete(threshold_values=True)]\n",
    ")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5), FillHoles(connectivity=4)])\n",
    "\n",
    "saver = SaveImage(output_dir=save_dir, output_ext=\".nii.gz\", output_postfix=\"DL\")\n",
    "\n",
    "load_path = f'dir/QSMmask_net_parameters.pth'\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(dataloader):\n",
    "        images = d[\"image\"].to(device)\n",
    "        [bs,c, xs,ys,zs] = images.size()\n",
    "        print(images.size())\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        pred_outputs = sliding_window_inference(inputs=images, roi_size=(int(0.7*xs),int(0.7*ys),int(0.5*zs)), sw_batch_size=2, predictor=model,overlap=0.5)          \n",
    "        pred_outputs = post_trans(pred_outputs[0])\n",
    "        print(pred_outputs.size())\n",
    "        \n",
    "input_data=nib.load(valid_brain[0])\n",
    "pred_outputs_cpu = (np.array(pred_outputs[0].cpu()))\n",
    "plt.imshow(pred_outputs_cpu[:,:,int(zs/2)])\n",
    "                        \n",
    "\n",
    "save_output_data = nib.Nifti1Image(pred_outputs_cpu, input_data.affine, input_data.header)\n",
    "nib.save(save_output_data,f'{save_dir}/QSMmask-net_mask.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
